{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripletCough: Cougher Identification and Verification from Contact-Free Smartphone-Based Audio Recordings Using Metric Learning\n",
    "We have already trained our TripletCough network on a data set of voluntary coughs recorded using the RÃ˜DE NT1000 studio microphone, as described in the paper. We provide you with the pre-trained model file in `weights_testing/rode_close/20201108_065654__Parameters_rode_close_weights.h5`. The code used to evaluate this pre-trained model can be found in the  section \"Python Scripts\" which explains how to run the various python scripts available for performing the identification and verification tests that are reported in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.05\n",
      "FAR:  1.0\n",
      "FRR:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define the relevant variables (number of enrollment and test samples, etc.)\n",
    "nb_participants = 20\n",
    "nb_enrollment_samples = 10\n",
    "nb_test_samples = 5\n",
    "\n",
    "# Define the expected size of the spectrogram\n",
    "spect_height = 80\n",
    "spect_width = 237\n",
    "\n",
    "# Define threshold for decision rule\n",
    "THRESHOLD = 2.2\n",
    "\n",
    "# Load Model\n",
    "from Model import get_triplet_network, get_embedding_cnn\n",
    "model = get_triplet_network((spect_height, spect_width, 1))\n",
    "embedding_cnn = get_embedding_cnn((spect_height, spect_width, 1))\n",
    "\n",
    "# 20 participants with 10 enrollment samples each\n",
    "X_enrollment = np.random.rand(nb_participants, nb_enrollment_samples, spect_height, spect_width)\n",
    "n_samples_enrollment = [nb_enrollment_samples] * nb_participants\n",
    "\n",
    "# 20 participants with 5 test samples each\n",
    "X_test = np.random.rand(nb_participants, nb_test_samples, spect_height, spect_width)\n",
    "n_samples_test = [nb_test_samples] * nb_participants\n",
    "\n",
    "weights_file = os.path.join(\".\", \"weights_testing\", \"rode_close\", \"20201108_065654__Parameters_rode_close_weights.h5\")\n",
    "\n",
    "# Load weights\n",
    "model.load_weights(weights_file)\n",
    "embedding_cnn.set_weights(model.get_weights())\n",
    "\n",
    "tp, fp, tn, fn = 4 * [0]\n",
    "\n",
    "for participant in range(nb_participants):\n",
    "    # Select the remaining n_test samples (different from the enrollment samples) from P1 as test samples\n",
    "    remaining_participant_list = list(range(nb_participants))\n",
    "    remaining_participant_list.remove(participant)\n",
    "\n",
    "    # Retrieve images from P1\n",
    "    P1_enrollment = X_enrollment[participant, :, :, :].reshape(\n",
    "    nb_enrollment_samples, spect_height, spect_width, 1\n",
    "    )\n",
    "    P1_test = X_test[participant, :, :, :].reshape(nb_test_samples, spect_height, spect_width, 1)\n",
    "\n",
    "    test_samples = X_test[remaining_participant_list, :, :, :].reshape(len(remaining_participant_list * nb_test_samples), spect_height, spect_width, 1)\n",
    "\n",
    "    # Compute the embeddings\n",
    "    emb_P1_enrollment = embedding_cnn.predict(P1_enrollment)\n",
    "    emb_P1_test = embedding_cnn.predict(P1_test)\n",
    "    emb_others = embedding_cnn.predict(test_samples)\n",
    "\n",
    "    m = tf.keras.metrics.MeanTensor()\n",
    "    \n",
    "    for test_sample in emb_P1_test:\n",
    "        for enrollment_sample in emb_P1_enrollment:\n",
    "            distance = K.sum(K.square(test_sample - enrollment_sample), axis=0)\n",
    "            m.update_state(distance)\n",
    "        mean_distance = m.result()\n",
    "        if mean_distance < THRESHOLD:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "        m.reset_states()\n",
    "\n",
    "    for test_sample in emb_others:\n",
    "        for enrollment_sample in emb_P1_enrollment:\n",
    "            distance = K.sum(K.square(test_sample - enrollment_sample), axis=0)\n",
    "            m.update_state(distance)\n",
    "        mean_distance = m.result()\n",
    "        if mean_distance < THRESHOLD:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "        m.reset_states()\n",
    "    \n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "far = fp / (fp + tn)\n",
    "frr = fn / (fn + tp)\n",
    "\n",
    "print(\"ACC: \", acc)\n",
    "print(\"FAR: \", far)\n",
    "print(\"FRR: \", frr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification Task (2-way 4-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  0.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  100.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  0.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  100.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  100.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  100.0\n",
      "ACC:  100.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  100.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  100.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  100.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  0.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  0.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  0.0\n",
      "ACC:  0.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  0.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  20.0\n",
      "ACC:  100.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  100.0\n",
      "ACC:  100.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  0.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  0.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  0.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  20.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  100.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  100.0\n",
      "ACC:  100.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  100.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  40.0\n",
      "ACC:  0.0\n",
      "ACC:  20.0\n",
      "ACC:  60.0\n",
      "ACC:  100.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "ACC:  80.0\n",
      "ACC:  60.0\n",
      "ACC:  40.0\n",
      "ACC:  40.0\n",
      "ACC:  60.0\n",
      "ACC:  20.0\n",
      "ACC:  40.0\n",
      "ACC:  80.0\n",
      "\n",
      "Mean ACC:  51.578947368421055\n"
     ]
    }
   ],
   "source": [
    "from Model import get_triplet_network, get_embedding_cnn\n",
    "from itertools import permutations\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy.random as rng\n",
    "\n",
    "nb_participants = 20\n",
    "nb_enrollment_samples = 10\n",
    "nb_test_samples = 5\n",
    "spect_height = 80\n",
    "spect_width = 237\n",
    "\n",
    "# Identification task\n",
    "n_tasks = 5\n",
    "k = 4 # 4-shot evaluation\n",
    "\n",
    "# Load Model\n",
    "model = get_triplet_network((spect_height, spect_width, 1))\n",
    "embedding_cnn = get_embedding_cnn((spect_height, spect_width, 1))\n",
    "\n",
    "# Generate the Testing Data from Pickle File\n",
    "# 20 participants with 10 enrollment samples each\n",
    "X = np.random.rand(nb_participants, nb_enrollment_samples, spect_height, spect_width)\n",
    "n_samples = [nb_enrollment_samples] * nb_participants\n",
    "\n",
    "# Write header line to csv file\n",
    "permutation_list = list(permutations(range(X.shape[0]), 2))\n",
    "permutation_list.insert(0, \"Participant Combinations\")\n",
    "\n",
    "# Loaded the pre-trained weight file\n",
    "weights_path = os.path.join(\".\", \"weights_testing\", \"rode_close\", \"20201108_065654__Parameters_rode_close_weights.h5\")\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load weights\n",
    "model.load_weights(weights_path)\n",
    "embedding_cnn.set_weights(model.get_weights())\n",
    "\n",
    "acc_model = []\n",
    "count = 0\n",
    "# Loop over all participant combinations\n",
    "for participant_combo in permutations(range(X.shape[0]), 2):\n",
    "    n_test = 0\n",
    "    n_correct = 0\n",
    "\n",
    "    # For each pair of participants, generate n_tasks (default: 100) random 2-way-k-shot tasks and\n",
    "    # evaluate accuracy over these tasks\n",
    "    for i in range(0, n_tasks):\n",
    "\n",
    "        # First select k+1 samples u.a.r. from P1\n",
    "        P1_samples = rng.choice(range(n_samples[participant_combo[0]]), size=(k + 1,), replace=False)\n",
    "        # Select first sample from P1 as test sample\n",
    "        P1_test_sample = P1_samples[0]\n",
    "        # Select the other k samples (different from the test sample) from P1 as anchor samples\n",
    "        P1_anchor_samples = P1_samples[1:]\n",
    "\n",
    "        # Select k samples u.a.r. from P2 as anchor samples\n",
    "        P2_anchor_samples = rng.choice(range(n_samples[participant_combo[1]]), size=(k,), replace=False)\n",
    "\n",
    "        # Retrieve images from test and anchor samples\n",
    "        test_img = X[participant_combo[0], P1_test_sample, :, :].reshape(1, spect_height, spect_width, 1)\n",
    "\n",
    "        P1_anchor_imgs = X[participant_combo[0], P1_anchor_samples, :, :].reshape(k, spect_height, spect_width, 1)\n",
    "        P2_anchor_imgs = X[participant_combo[1], P2_anchor_samples, :, :].reshape(k, spect_height, spect_width, 1)\n",
    "\n",
    "        # Create support set composed of k P1 and k P2 anchor images\n",
    "        support_set = np.concatenate((P1_anchor_imgs, P2_anchor_imgs), axis=0)\n",
    "\n",
    "        # Test model\n",
    "        # Compute embeddings for test sample and for each anchor sample in support set\n",
    "        embedding_test_img = embedding_cnn.predict(test_img)\n",
    "        embedding_support_set = embedding_cnn.predict(support_set)\n",
    "\n",
    "        distances = []\n",
    "\n",
    "        # Compute distances between embeddings of test sample and each anchor sample in support set\n",
    "        for emb in embedding_support_set:\n",
    "            distances.append(K.sum(K.square(embedding_test_img - emb), axis=1))\n",
    "\n",
    "        # Compute mean distance between test sample and anchor samples of P1 / test sample and anchor samples of P2\n",
    "        m = tf.keras.metrics.MeanTensor()\n",
    "\n",
    "        for i in range(0, k):\n",
    "            m.update_state(distances[i])\n",
    "\n",
    "        P1_mean_distance = m.result()\n",
    "\n",
    "        m.reset_states()\n",
    "\n",
    "        for i in range(k, len(distances)):\n",
    "            m.update_state(distances[i])\n",
    "\n",
    "        P2_mean_distance = m.result()\n",
    "\n",
    "        if P1_mean_distance < P2_mean_distance:\n",
    "            n_correct += 1\n",
    "\n",
    "    # Compute k-shot test accuracy for this participant combination\n",
    "    acc = 100.0 * n_correct / n_tasks\n",
    "    print(\"ACC: \", acc)\n",
    "    acc_model.append(acc)\n",
    "    count += n_tasks\n",
    "\n",
    "print()\n",
    "print(\"Mean ACC: \", (sum(acc_model)/len(acc_model)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d443351426022e793d8b9cb3f6aa2fd5560400263429ced6725f6d598bcd598c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
